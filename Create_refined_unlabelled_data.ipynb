{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOlNPfy0LrdZGcxF8T4zWp3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jhy9968/ECE6179_project/blob/main/Create_refined_unlabelled_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFBpiWvvDE4N",
        "outputId": "5848d98b-e5df-48ce-dad0-e0e0b0ae2231"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchvision.datasets import STL10 as STL10\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import random_split\n",
        "import torchvision\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "####### CHANGE TO APPROPRIATE DIRECTORY TO STORE DATASET\n",
        "root_dir = \"/content/drive/Shareddrives/ECE6179_project/\"\n",
        "dataset_dir = root_dir + \"CNN-VAE/data/\"\n",
        "#For MonARCH\n",
        "# dataset_dir = \"/mnt/lustre/projects/ds19/SHARED\"\n",
        "\n",
        "#All images are 3x96x96\n",
        "image_size = 96"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7wXg8yiPDE4Q"
      },
      "outputs": [],
      "source": [
        "transform_unlabelled = transforms.Compose(\n",
        "    [transforms.RandomHorizontalFlip(p=0.5),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DouBlqObDE4V",
        "outputId": "cda486b6-fd23-40ee-d21f-33054f6177d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "unlabelled_set = STL10(dataset_dir, split='unlabeled', transform=transform_unlabelled, download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "qVrmhgwmDE4X",
        "outputId": "8e7223f2-3dc1-4b7b-8396-3377fbe0a0c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of unlabelled loader: 1563\n",
            "Batch size: 64\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "unlabelled_loader = DataLoader(unlabelled_set, shuffle=False, batch_size=batch_size)\n",
        "\n",
        "print('Size of unlabelled loader:', len(unlabelled_loader))\n",
        "print('Batch size:', batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "model = torchvision.models.resnet18()\n",
        "model.fc = torch.nn.Linear(in_features=512, out_features=10, bias=True)\n",
        "model = model.to(device)\n",
        "model.load_state_dict(torch.load(root_dir+'Baseline_resnet18/models/trained_baseline18'))\n",
        "\n",
        "softmax = torch.nn.Softmax()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGInrDETL9KP",
        "outputId": "3d1ec509-99e1-49d9-e37b-67358671c053"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out_list = []\n",
        "\n",
        "for images, labels in unlabelled_loader:\n",
        "  images = images.to(device)\n",
        "  with torch.no_grad():\n",
        "    out = model(images)\n",
        "    out_list.append(softmax(out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6AEUggPPZcM",
        "outputId": "48889ac7-ed57-411f-8dcf-b93d90a1857d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  import sys\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_out = torch.cat(out_list, dim=0)\n",
        "print(all_out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3NMGDV7Z6if",
        "outputId": "10e8e4bd-e655-4ed9-8a09-e9693dc49728"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100000, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "refined_images = []\n",
        "K = 1000\n",
        "\n",
        "for i in range(10): \n",
        "  col = all_out[:,i].cpu().detach().numpy()\n",
        "  ind = np.argpartition(col, -K)[-K:]\n",
        "  for j in ind:\n",
        "    refined_images.append(unlabelled_set[j][0])\n",
        "\n",
        "refined_images = torch.stack(refined_images)\n",
        "print(refined_images.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uWpHnmKaI44",
        "outputId": "2cd65379-603b-4185-c6ab-7a5639de849c"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10000, 3, 96, 96])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(refined_images, dataset_dir+'refined_images.pt')"
      ],
      "metadata": {
        "id": "AxsH-NccensP"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Create dataset and dataloader for the refined data\n",
        "\n"
      ],
      "metadata": {
        "id": "MNEvBcMYil6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class Refined_Unlabelled_Dataset(Dataset):\n",
        "    def __init__(self, img_dir, transform=None):\n",
        "        self.images = torch.load(img_dir)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.images.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[i]\n",
        "        label = -1\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "v_OaXczGjIIV"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = \"/content/drive/Shareddrives/ECE6179_project/\"\n",
        "dataset_dir = root_dir + \"CNN-VAE/data/\"\n",
        "refined_unlabelled_set = Refined_Unlabelled_Dataset(img_dir=dataset_dir+'refined_images.pt')"
      ],
      "metadata": {
        "id": "ppNO6Bonkr3G"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "refined_unlabelled_loader = DataLoader(refined_unlabelled_set, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "JefB_wqAk_J2"
      },
      "execution_count": 78,
      "outputs": []
    }
  ]
}