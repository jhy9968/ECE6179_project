{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOy3F7w68bMy1hzYk2MUXLB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jhy9968/ECE6179_project/blob/main/Baseline_ResNet18.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-S0T_NpRDE4J"
      },
      "source": [
        "<h1> ECE4179 - Semi-Supervised Learning Project</h1>\n",
        "<h2>Data</h2>\n",
        "\n",
        "We will be using a dataset that can be obtained directly from the torchvision package. There are 10 classes and we will be training a CNN for the image classification task. We have training, validation and test sets that are labelled with the class, and a large unlabeled set.\n",
        "\n",
        "We will simulating a low training data scenario by only sampling a small percentage of the labelled data (10%) as training data. The remaining examples will be used as the validation set.\n",
        "\n",
        "To get the labelled data, change the dataset_dir to something suitable for your machine, and execute the following (you will then probably want to wrap the dataset objects in a PyTorch DataLoader):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFBpiWvvDE4N",
        "outputId": "82e2b030-31f5-4bec-f798-ea0e2d4225c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchvision.datasets import STL10 as STL10\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import random_split\n",
        "import torchvision\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "####### CHANGE TO APPROPRIATE DIRECTORY TO STORE DATASET\n",
        "dataset_dir = \"/content/drive/Shareddrives/ECE6179_project/CNN-VAE/data/\"\n",
        "#For MonARCH\n",
        "# dataset_dir = \"/mnt/lustre/projects/ds19/SHARED\"\n",
        "\n",
        "#All images are 3x96x96\n",
        "image_size = 96\n",
        "#Example batch size\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLcOWpnFDE4P"
      },
      "source": [
        "<h3>Create the appropriate transforms</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7wXg8yiPDE4Q"
      },
      "outputs": [],
      "source": [
        "#Perform random crops and mirroring for data augmentation\n",
        "transform_train = transforms.Compose(\n",
        "    [transforms.RandomCrop(image_size, padding=4),\n",
        "     transforms.RandomHorizontalFlip(p=0.5),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "transform_unlabelled = transforms.Compose(\n",
        "    [transforms.RandomHorizontalFlip(p=0.5),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "#No random \n",
        "transform_test = transforms.Compose(\n",
        "    [transforms.CenterCrop(image_size),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AS3dubNXDE4S"
      },
      "source": [
        "<h3>Create training and validation split</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rgiNAlXDE4T",
        "outputId": "5428abc2-28cb-4230-fed2-347c85480b71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "#Load train and validation sets\n",
        "trainval_set = STL10(dataset_dir, split='train', transform=transform_train, download=True)\n",
        "\n",
        "#Use 10% of data for training - simulating low data scenario\n",
        "num_train = int(len(trainval_set)*0.1)\n",
        "\n",
        "#Split data into train/val sets\n",
        "torch.manual_seed(0) #Set torch's random seed so that random split of data is reproducible\n",
        "train_set, val_set = random_split(trainval_set, [num_train, len(trainval_set)-num_train])\n",
        "\n",
        "#Load test set\n",
        "test_set = STL10(dataset_dir, split='test', transform=transform_test, download=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqG_W11HDE4U"
      },
      "source": [
        "<h3>Get the unlabelled data</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DouBlqObDE4V",
        "outputId": "1a45e4e0-cba0-4f1b-ce0d-bf9cd881b67d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "unlabelled_set = STL10(dataset_dir, split='unlabeled', transform=transform_unlabelled, download=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQqKNndoDE4W"
      },
      "source": [
        "You may find later that you want to make changes to how the unlabelled data is loaded. This might require you sub-classing the STL10 class used above or to create your own dataloader similar to the Pytorch one.\n",
        "https://pytorch.org/docs/stable/_modules/torchvision/datasets/stl10.html#STL10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMURqvriDE4X"
      },
      "source": [
        "<h3>Create the four dataloaders</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qVrmhgwmDE4X"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_set, shuffle=True, batch_size=batch_size)\n",
        "unlabelled_loader = DataLoader(unlabelled_set, shuffle=True, batch_size=batch_size)\n",
        "\n",
        "valid_loader = DataLoader(val_set, batch_size=batch_size)\n",
        "test_loader  = DataLoader(test_set, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJLvtfofDE4Z"
      },
      "source": [
        "## Network\n",
        "\n",
        "Let's use a ResNet18 architecture for our CNN..."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# print(device)"
      ],
      "metadata": {
        "id": "NwWBSwHuQXYr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "M6kttFtVDE4a"
      },
      "outputs": [],
      "source": [
        "model = torchvision.models.resnet18()\n",
        "# model = model.to(device)\n",
        "optimiser = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(epoch_index, tb_writer):\n",
        "    running_loss = 0.\n",
        "    last_loss = 0.\n",
        "\n",
        "    for i, data in enumerate(train_loader):\n",
        "        inputs, labels = data\n",
        "        # inputs = inputs.to(device)\n",
        "        # labels = labels.to(device)\n",
        "\n",
        "        optimiser.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        optimiser.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 1000 == 999:\n",
        "            last_loss = running_loss / 1000 # loss per batch\n",
        "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
        "            tb_x = epoch_index * len(train_loader) + i + 1\n",
        "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
        "            running_loss = 0.\n",
        "\n",
        "    # del inputs\n",
        "    # del labels\n",
        "    # torch.cuda.empty_cache()\n",
        "\n",
        "    return last_loss"
      ],
      "metadata": {
        "id": "5PUZTMixHeNY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
        "epoch_number = 0\n",
        "\n",
        "EPOCHS = 5\n",
        "\n",
        "best_vloss = 1_000_000.\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print('EPOCH {}:'.format(epoch_number + 1))\n",
        "\n",
        "    model.train(True)\n",
        "    avg_loss = train_one_epoch(epoch_number, writer)\n",
        "\n",
        "    model.train(False)\n",
        "\n",
        "    running_vloss = 0.0\n",
        "    for i, vdata in enumerate(valid_loader):\n",
        "        vinputs, vlabels = vdata\n",
        "        # vinputs = vinputs.to(device)\n",
        "        # vlabels = vlabels.to(device)\n",
        "        voutputs = model(vinputs)\n",
        "        vloss = loss_fn(voutputs, vlabels)\n",
        "        running_vloss += vloss\n",
        "\n",
        "    avg_vloss = running_vloss / (i + 1)\n",
        "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
        "\n",
        "    writer.add_scalars('Training vs. Validation Loss',\n",
        "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
        "                    epoch_number + 1)\n",
        "    writer.flush()\n",
        "\n",
        "    # Track best performance, and save the model's state\n",
        "    if avg_vloss < best_vloss:\n",
        "        best_vloss = avg_vloss\n",
        "        # model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
        "        # torch.save(model.state_dict(), model_path)\n",
        "\n",
        "    epoch_number += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-d5cGjqVLHCR",
        "outputId": "3c9f0f45-6548-4090-9a14-f528f503fb26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 1:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4VF9Z91XPs1V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}