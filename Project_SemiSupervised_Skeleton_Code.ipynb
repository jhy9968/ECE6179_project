{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-S0T_NpRDE4J"
      },
      "source": [
        "<h1> ECE4179 - Semi-Supervised Learning Project</h1>\n",
        "<h2>Data</h2>\n",
        "\n",
        "We will be using a dataset that can be obtained directly from the torchvision package. There are 10 classes and we will be training a CNN for the image classification task. We have training, validation and test sets that are labelled with the class, and a large unlabeled set.\n",
        "\n",
        "We will simulating a low training data scenario by only sampling a small percentage of the labelled data (10%) as training data. The remaining examples will be used as the validation set.\n",
        "\n",
        "To get the labelled data, change the dataset_dir to something suitable for your machine, and execute the following (you will then probably want to wrap the dataset objects in a PyTorch DataLoader):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFBpiWvvDE4N",
        "outputId": "67107aa7-72b2-4f9a-e5de-a107014a0a29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchvision.datasets import STL10 as STL10\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import random_split\n",
        "import torchvision\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "####### CHANGE TO APPROPRIATE DIRECTORY TO STORE DATASET\n",
        "dataset_dir = \"/content/drive/Shareddrives/ECE6179_project/CNN-VAE/data/\"\n",
        "#For MonARCH\n",
        "# dataset_dir = \"/mnt/lustre/projects/ds19/SHARED\"\n",
        "\n",
        "#All images are 3x96x96\n",
        "image_size = 96\n",
        "#Example batch size\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLcOWpnFDE4P"
      },
      "source": [
        "<h3>Create the appropriate transforms</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7wXg8yiPDE4Q"
      },
      "outputs": [],
      "source": [
        "#Perform random crops and mirroring for data augmentation\n",
        "transform_train = transforms.Compose(\n",
        "    [transforms.RandomCrop(image_size, padding=4),\n",
        "     transforms.RandomHorizontalFlip(p=0.5),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "transform_unlabelled = transforms.Compose(\n",
        "    [transforms.RandomHorizontalFlip(p=0.5),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "#No random \n",
        "transform_test = transforms.Compose(\n",
        "    [transforms.CenterCrop(image_size),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AS3dubNXDE4S"
      },
      "source": [
        "<h3>Create training and validation split</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rgiNAlXDE4T",
        "outputId": "08152872-fdbb-42cb-a2e6-5b8c17933e84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "#Load train and validation sets\n",
        "trainval_set = STL10(dataset_dir, split='train', transform=transform_train, download=True)\n",
        "\n",
        "#Use 10% of data for training - simulating low data scenario\n",
        "num_train = int(len(trainval_set)*0.1)\n",
        "\n",
        "#Split data into train/val sets\n",
        "torch.manual_seed(0) #Set torch's random seed so that random split of data is reproducible\n",
        "train_set, val_set = random_split(trainval_set, [num_train, len(trainval_set)-num_train])\n",
        "\n",
        "#Load test set\n",
        "test_set = STL10(dataset_dir, split='test', transform=transform_test, download=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqG_W11HDE4U"
      },
      "source": [
        "<h3>Get the unlabelled data</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DouBlqObDE4V",
        "outputId": "dccbc615-cd4c-43f4-d50d-f655df5c6ba6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "unlabelled_set = STL10(dataset_dir, split='unlabeled', transform=transform_unlabelled, download=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQqKNndoDE4W"
      },
      "source": [
        "You may find later that you want to make changes to how the unlabelled data is loaded. This might require you sub-classing the STL10 class used above or to create your own dataloader similar to the Pytorch one.\n",
        "https://pytorch.org/docs/stable/_modules/torchvision/datasets/stl10.html#STL10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMURqvriDE4X"
      },
      "source": [
        "<h3>Create the four dataloaders</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "qVrmhgwmDE4X"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_set, shuffle=True, batch_size=batch_size)\n",
        "unlabelled_loader = DataLoader(unlabelled_set, shuffle=True, batch_size=batch_size)\n",
        "\n",
        "valid_loader = DataLoader(val_set, batch_size=batch_size)\n",
        "test_loader  = DataLoader(test_set, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJLvtfofDE4Z"
      },
      "source": [
        "## Network\n",
        "\n",
        "Let's use a ResNet18 architecture for our CNN..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6kttFtVDE4a"
      },
      "outputs": [],
      "source": [
        "model = torchvision.models.resnet18()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}